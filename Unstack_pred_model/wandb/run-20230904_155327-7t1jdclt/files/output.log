
 37%|███▋      | 14213/38400 [00:01<00:02, 8852.42it/s]
this is para_dict
 {'device': 'cuda:0', 'num_img': 48000, 'ratio': 0.8, 'epoch': 300, 'model_path': './results/MLP_902_2/', 'input_data_path': '../../knolling_dataset/MLP_unstack_902/labels_box/', 'output_data_path': '../../knolling_dataset/MLP_unstack_902/labels_unstack/', 'learning_rate': 0.001, 'patience': 10, 'factor': 0.1, 'batch_size': 64, 'output_size': 6, 'abort_learning': 20, 'set_dropout': 0.1, 'num_boxes': 5, 'run_name': 'MLP_902_2', 'project_name': 'zzz_MLP_unstack', 'wandb_flag': True, 'use_mse': True, 'use_scaler': False, 'fine-tuning': False, 'node_1': 128, 'node_2': 32, 'node_3': 8}

 83%|████████▎ | 32029/38400 [00:03<00:00, 8956.36it/s]
total train data: 38400
load the valid data ...
100%|██████████| 38400/38400 [00:04<00:00, 8886.60it/s]
100%|██████████| 9600/9600 [00:01<00:00, 8997.89it/s]
not fine-tuning
Training_Loss At Epoch 0:	 0.295005
Testing_Loss At Epoch 0:	 0.243372
epoch0, time used: 1.41, lr: 0.001
Training_Loss At Epoch 1:	 0.232718
Testing_Loss At Epoch 1:	 0.22141
epoch1, time used: 0.78, lr: 0.001
Training_Loss At Epoch 2:	 0.215586
Testing_Loss At Epoch 2:	 0.20872
epoch2, time used: 0.9, lr: 0.001
epoch3, time used: 0.8, lr: 0.001
Training_Loss At Epoch 4:	 0.18564
Testing_Loss At Epoch 4:	 0.183376
epoch4, time used: 0.86, lr: 0.001
Training_Loss At Epoch 5:	 0.180133
Testing_Loss At Epoch 5:	 0.180491
epoch5, time used: 0.88, lr: 0.001
Training_Loss At Epoch 6:	 0.176261
Testing_Loss At Epoch 6:	 0.179044
epoch6, time used: 0.74, lr: 0.001
Training_Loss At Epoch 7:	 0.172278
Testing_Loss At Epoch 7:	 0.175886
epoch7, time used: 0.84, lr: 0.001
epoch8, time used: 0.78, lr: 0.001
Training_Loss At Epoch 9:	 0.167233
Testing_Loss At Epoch 9:	 0.172189
epoch9, time used: 0.83, lr: 0.001
Training_Loss At Epoch 10:	 0.164675
Testing_Loss At Epoch 10:	 0.168446
epoch10, time used: 0.81, lr: 0.001
Training_Loss At Epoch 11:	 0.162013
Testing_Loss At Epoch 11:	 0.165438
epoch11, time used: 0.78, lr: 0.001
Training_Loss At Epoch 12:	 0.16106
Testing_Loss At Epoch 12:	 0.165429
epoch12, time used: 0.73, lr: 0.001
epoch13, time used: 0.74, lr: 0.001
epoch14, time used: 1.03, lr: 0.001
epoch15, time used: 0.82, lr: 0.001
Training_Loss At Epoch 16:	 0.155271
Testing_Loss At Epoch 16:	 0.160594
epoch16, time used: 0.77, lr: 0.001
Training_Loss At Epoch 17:	 0.155258
Testing_Loss At Epoch 17:	 0.159961
epoch17, time used: 0.78, lr: 0.001
epoch18, time used: 0.68, lr: 0.001
epoch19, time used: 0.67, lr: 0.001
epoch20, time used: 0.68, lr: 0.001
epoch21, time used: 0.75, lr: 0.001
Training_Loss At Epoch 22:	 0.15046
Testing_Loss At Epoch 22:	 0.158308
epoch22, time used: 0.81, lr: 0.001
Training_Loss At Epoch 23:	 0.149427
Testing_Loss At Epoch 23:	 0.15782
epoch23, time used: 0.8, lr: 0.001
epoch24, time used: 0.8, lr: 0.001
epoch25, time used: 0.78, lr: 0.001
Training_Loss At Epoch 26:	 0.14727
Testing_Loss At Epoch 26:	 0.15452
epoch26, time used: 0.8, lr: 0.001
epoch27, time used: 0.79, lr: 0.001
epoch28, time used: 0.76, lr: 0.001
epoch29, time used: 0.82, lr: 0.001
epoch30, time used: 0.88, lr: 0.001
Training_Loss At Epoch 31:	 0.144114
Testing_Loss At Epoch 31:	 0.153605
epoch31, time used: 0.76, lr: 0.001
epoch32, time used: 0.76, lr: 0.001
epoch33, time used: 0.74, lr: 0.001
epoch34, time used: 0.78, lr: 0.001
Training_Loss At Epoch 35:	 0.142781
Testing_Loss At Epoch 35:	 0.151368
epoch35, time used: 0.77, lr: 0.001
Training_Loss At Epoch 36:	 0.141545
Testing_Loss At Epoch 36:	 0.151116
epoch36, time used: 0.76, lr: 0.001
epoch37, time used: 0.78, lr: 0.001
epoch38, time used: 0.77, lr: 0.001
epoch39, time used: 0.78, lr: 0.001
epoch40, time used: 0.73, lr: 0.001
epoch41, time used: 0.76, lr: 0.001
epoch42, time used: 0.78, lr: 0.001
Training_Loss At Epoch 43:	 0.136627
Testing_Loss At Epoch 43:	 0.150007
epoch43, time used: 0.78, lr: 0.001
epoch44, time used: 0.79, lr: 0.001
epoch45, time used: 0.77, lr: 0.001
epoch46, time used: 0.77, lr: 0.001
Training_Loss At Epoch 47:	 0.13565
Testing_Loss At Epoch 47:	 0.148779
epoch47, time used: 0.78, lr: 0.001
epoch48, time used: 0.78, lr: 0.001
epoch49, time used: 0.78, lr: 0.001
epoch50, time used: 0.77, lr: 0.001
epoch51, time used: 0.77, lr: 0.001
epoch52, time used: 0.78, lr: 0.001
epoch53, time used: 0.78, lr: 0.001
epoch54, time used: 0.78, lr: 0.001
Training_Loss At Epoch 55:	 0.131277
Testing_Loss At Epoch 55:	 0.148475
epoch55, time used: 0.78, lr: 0.001
epoch56, time used: 0.79, lr: 0.001
epoch57, time used: 0.77, lr: 0.001
epoch58, time used: 0.78, lr: 0.001
epoch59, time used: 0.78, lr: 0.001
epoch60, time used: 0.77, lr: 0.001
epoch61, time used: 0.78, lr: 0.001
epoch62, time used: 0.77, lr: 0.001
epoch63, time used: 0.78, lr: 0.001
Training_Loss At Epoch 64:	 0.127817
Testing_Loss At Epoch 64:	 0.14693
epoch64, time used: 0.75, lr: 0.001
epoch65, time used: 0.78, lr: 0.001
epoch66, time used: 0.77, lr: 0.001
epoch67, time used: 0.79, lr: 0.001
epoch68, time used: 0.76, lr: 0.001
epoch69, time used: 0.77, lr: 0.001
epoch70, time used: 0.73, lr: 0.001
epoch71, time used: 0.76, lr: 0.001
epoch72, time used: 0.76, lr: 0.001
Training_Loss At Epoch 73:	 0.124777
Testing_Loss At Epoch 73:	 0.14633
epoch73, time used: 0.75, lr: 0.001
epoch74, time used: 0.78, lr: 0.001
epoch75, time used: 0.78, lr: 0.001
epoch76, time used: 0.77, lr: 0.001
epoch77, time used: 0.77, lr: 0.001
epoch78, time used: 0.77, lr: 0.001
epoch79, time used: 0.79, lr: 0.001
epoch80, time used: 0.77, lr: 0.001
epoch81, time used: 0.77, lr: 0.001
epoch82, time used: 0.78, lr: 0.001
epoch83, time used: 0.76, lr: 0.001
epoch84, time used: 0.78, lr: 0.001
Training_Loss At Epoch 85:	 0.112112
Testing_Loss At Epoch 85:	 0.143637
epoch85, time used: 0.77, lr: 0.0001
epoch86, time used: 0.78, lr: 0.0001
epoch87, time used: 0.76, lr: 0.0001
epoch88, time used: 0.76, lr: 0.0001
epoch89, time used: 0.77, lr: 0.0001
epoch90, time used: 0.76, lr: 0.0001
epoch91, time used: 0.76, lr: 0.0001
epoch92, time used: 0.73, lr: 0.0001
epoch93, time used: 0.78, lr: 0.0001
epoch94, time used: 0.71, lr: 0.0001
epoch95, time used: 0.67, lr: 0.0001
epoch96, time used: 0.73, lr: 0.0001
epoch97, time used: 0.73, lr: 1e-05
epoch98, time used: 0.77, lr: 1e-05
epoch99, time used: 0.77, lr: 1e-05
epoch100, time used: 0.77, lr: 1e-05
epoch101, time used: 0.77, lr: 1e-05
epoch102, time used: 0.77, lr: 1e-05
epoch103, time used: 0.76, lr: 1e-05
epoch104, time used: 0.78, lr: 1e-05
epoch105, time used: 0.72, lr: 1e-05
epoch106, time used: 0.77, lr: 1e-05