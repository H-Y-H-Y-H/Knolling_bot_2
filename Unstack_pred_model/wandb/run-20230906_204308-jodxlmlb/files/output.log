
 11%|█         | 13981/128000 [00:01<00:13, 8735.05it/s]
this is para_dict
 {'device': 'cuda:0', 'num_img': 160000, 'ratio': 0.8, 'epoch': 300, 'model_path': './results/MLP_905_1/', 'input_data_path': '../../knolling_dataset/MLP_unstack_905/labels_box/', 'output_data_path': '../../knolling_dataset/MLP_unstack_905/labels_unstack/', 'learning_rate': 0.001, 'patience': 10, 'factor': 0.1, 'batch_size': 64, 'output_size': 6, 'abort_learning': 20, 'set_dropout': 0.1, 'num_boxes': 5, 'run_name': 'MLP_905_1', 'project_name': 'zzz_MLP_unstack', 'wandb_flag': True, 'use_mse': True, 'use_scaler': False, 'fine-tuning': False, 'node_1': 128, 'node_2': 32, 'node_3': 8}






 89%|████████▉ | 113652/128000 [00:13<00:01, 8199.79it/s]
total train data: 128000
100%|██████████| 128000/128000 [00:15<00:00, 8338.75it/s]

 60%|██████    | 19249/32000 [00:02<00:01, 8316.94it/s]

100%|██████████| 32000/32000 [00:03<00:00, 8231.19it/s]
not fine-tuning
Training_Loss At Epoch 0:	 0.361464
Testing_Loss At Epoch 0:	 0.350809
epoch0, time used: 3.35, lr: 0.001
Training_Loss At Epoch 1:	 0.341895
Testing_Loss At Epoch 1:	 0.3422
epoch1, time used: 2.47, lr: 0.001
Training_Loss At Epoch 2:	 0.335634
Testing_Loss At Epoch 2:	 0.336579
epoch2, time used: 2.53, lr: 0.001
Training_Loss At Epoch 3:	 0.333386
Testing_Loss At Epoch 3:	 0.335118
epoch3, time used: 2.64, lr: 0.001
Training_Loss At Epoch 4:	 0.332111
Testing_Loss At Epoch 4:	 0.332208
epoch4, time used: 2.73, lr: 0.001
Training_Loss At Epoch 5:	 0.331187
Testing_Loss At Epoch 5:	 0.331777
epoch5, time used: 2.62, lr: 0.001
epoch6, time used: 2.45, lr: 0.001
Training_Loss At Epoch 7:	 0.330041
Testing_Loss At Epoch 7:	 0.330806
epoch7, time used: 2.57, lr: 0.001
epoch8, time used: 2.91, lr: 0.001
epoch9, time used: 2.69, lr: 0.001
epoch10, time used: 2.35, lr: 0.001
Training_Loss At Epoch 11:	 0.328221
Testing_Loss At Epoch 11:	 0.330122
epoch11, time used: 2.72, lr: 0.001
epoch12, time used: 2.64, lr: 0.001
Training_Loss At Epoch 13:	 0.327455
Testing_Loss At Epoch 13:	 0.329379
epoch13, time used: 2.84, lr: 0.001
Training_Loss At Epoch 14:	 0.327333
Testing_Loss At Epoch 14:	 0.32872
epoch14, time used: 2.61, lr: 0.001
epoch15, time used: 2.95, lr: 0.001
epoch16, time used: 3.0, lr: 0.001
epoch17, time used: 2.57, lr: 0.001
Training_Loss At Epoch 18:	 0.325819
Testing_Loss At Epoch 18:	 0.328688
epoch18, time used: 2.43, lr: 0.001
epoch19, time used: 2.65, lr: 0.001
epoch20, time used: 2.62, lr: 0.001
epoch21, time used: 2.53, lr: 0.001
epoch22, time used: 2.59, lr: 0.001
Training_Loss At Epoch 23:	 0.324551
Testing_Loss At Epoch 23:	 0.328311
epoch23, time used: 2.6, lr: 0.001
Training_Loss At Epoch 24:	 0.324092
Testing_Loss At Epoch 24:	 0.327178
epoch24, time used: 2.38, lr: 0.001
Training_Loss At Epoch 25:	 0.324091
Testing_Loss At Epoch 25:	 0.327096
epoch25, time used: 2.54, lr: 0.001
Training_Loss At Epoch 26:	 0.323942
Testing_Loss At Epoch 26:	 0.326582
epoch26, time used: 2.56, lr: 0.001
epoch27, time used: 2.72, lr: 0.001
epoch28, time used: 2.25, lr: 0.001
epoch29, time used: 2.97, lr: 0.001
epoch30, time used: 2.61, lr: 0.001
epoch31, time used: 2.61, lr: 0.001
Training_Loss At Epoch 32:	 0.322665
Testing_Loss At Epoch 32:	 0.326142
epoch32, time used: 2.63, lr: 0.001
epoch33, time used: 2.83, lr: 0.001
epoch34, time used: 2.54, lr: 0.001
Training_Loss At Epoch 35:	 0.322428
Testing_Loss At Epoch 35:	 0.325582
epoch35, time used: 3.0, lr: 0.001
epoch36, time used: 2.56, lr: 0.001
epoch37, time used: 2.63, lr: 0.001
epoch38, time used: 2.79, lr: 0.001
epoch39, time used: 2.57, lr: 0.001
epoch40, time used: 2.46, lr: 0.001
epoch41, time used: 2.83, lr: 0.001
epoch42, time used: 2.69, lr: 0.001
epoch43, time used: 3.0, lr: 0.001
Training_Loss At Epoch 44:	 0.320863
Testing_Loss At Epoch 44:	 0.325518
epoch44, time used: 2.57, lr: 0.001
epoch45, time used: 2.51, lr: 0.001
epoch46, time used: 2.34, lr: 0.001
epoch47, time used: 2.37, lr: 0.001
epoch48, time used: 2.73, lr: 0.001
epoch49, time used: 2.66, lr: 0.001
Training_Loss At Epoch 50:	 0.320141
Testing_Loss At Epoch 50:	 0.325477
epoch50, time used: 2.65, lr: 0.001
epoch51, time used: 2.57, lr: 0.001
epoch52, time used: 2.68, lr: 0.001
epoch53, time used: 2.75, lr: 0.001
Training_Loss At Epoch 54:	 0.319791
Testing_Loss At Epoch 54:	 0.325063
epoch54, time used: 2.68, lr: 0.001
epoch55, time used: 2.63, lr: 0.001
epoch56, time used: 2.71, lr: 0.001
epoch57, time used: 2.53, lr: 0.001
epoch58, time used: 2.63, lr: 0.001
epoch59, time used: 2.76, lr: 0.001
epoch60, time used: 2.57, lr: 0.001
epoch61, time used: 2.81, lr: 0.001
Training_Loss At Epoch 62:	 0.319074
Testing_Loss At Epoch 62:	 0.324979
epoch62, time used: 2.66, lr: 0.001
epoch63, time used: 2.69, lr: 0.001
epoch64, time used: 2.61, lr: 0.001
epoch65, time used: 2.63, lr: 0.001
Training_Loss At Epoch 66:	 0.318354
Testing_Loss At Epoch 66:	 0.32484
epoch66, time used: 2.64, lr: 0.001
epoch67, time used: 2.63, lr: 0.001
epoch68, time used: 2.67, lr: 0.001
Training_Loss At Epoch 69:	 0.318118
Testing_Loss At Epoch 69:	 0.324759
epoch69, time used: 2.7, lr: 0.001
epoch70, time used: 2.62, lr: 0.001
epoch71, time used: 2.74, lr: 0.001
Training_Loss At Epoch 72:	 0.31803
Testing_Loss At Epoch 72:	 0.324634
epoch72, time used: 2.71, lr: 0.001
epoch73, time used: 2.6, lr: 0.001
epoch74, time used: 2.9, lr: 0.001
epoch75, time used: 2.63, lr: 0.001
epoch76, time used: 2.65, lr: 0.001
epoch77, time used: 2.45, lr: 0.001
Training_Loss At Epoch 78:	 0.317663
Testing_Loss At Epoch 78:	 0.324234
epoch78, time used: 2.43, lr: 0.001
epoch79, time used: 2.64, lr: 0.001
epoch80, time used: 2.45, lr: 0.001
epoch81, time used: 2.69, lr: 0.001
epoch82, time used: 2.54, lr: 0.001
epoch83, time used: 2.65, lr: 0.001
epoch84, time used: 2.6, lr: 0.001
epoch85, time used: 2.49, lr: 0.001
epoch86, time used: 2.44, lr: 0.001
epoch87, time used: 2.45, lr: 0.001
epoch88, time used: 2.62, lr: 0.001
epoch89, time used: 2.58, lr: 0.001
Training_Loss At Epoch 90:	 0.312748
Testing_Loss At Epoch 90:	 0.323895
epoch90, time used: 2.43, lr: 0.0001
epoch91, time used: 2.63, lr: 0.0001
epoch92, time used: 2.41, lr: 0.0001
epoch93, time used: 2.51, lr: 0.0001
epoch94, time used: 2.53, lr: 0.0001
epoch95, time used: 2.68, lr: 0.0001
epoch96, time used: 2.78, lr: 0.0001
epoch97, time used: 2.8, lr: 0.0001
epoch98, time used: 2.6, lr: 0.0001
epoch99, time used: 2.66, lr: 0.0001
epoch100, time used: 2.63, lr: 0.0001
epoch101, time used: 2.6, lr: 0.0001
epoch102, time used: 2.27, lr: 1e-05
epoch103, time used: 2.63, lr: 1e-05
epoch104, time used: 2.28, lr: 1e-05
epoch105, time used: 2.4, lr: 1e-05
epoch106, time used: 2.5, lr: 1e-05
epoch107, time used: 2.31, lr: 1e-05
epoch108, time used: 2.26, lr: 1e-05
epoch109, time used: 2.64, lr: 1e-05
epoch110, time used: 2.5, lr: 1e-05
epoch111, time used: 2.51, lr: 1e-05